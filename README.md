# Notification_UX_XR
Demonstrating how a user can interact with the notofications in AR/MR HMDs<br>
This prototype is a part of my Multi-Modal Interaction Design project.

<h2>Problem Statement</h2>
<p> User might not feel comfort to use their hand to point towards the buttons or UI elements to interact all the time</p>
<p> <strong>User Scenario:</strong> When an AR/MR HMD wearer who is traveling in a public transport gets a notifcation, he/she might not want raise their hands to mid air to press the read/dismiss button</p><br>

![Notifications---WIP](https://user-images.githubusercontent.com/65128826/232402078-2aa86f32-6ec2-4c43-b5cc-335237747bc0.gif)



<h2>Proposed Solution</h2>
<p> Apart from the hand gesture modality, the user can have the choice of using other modalities(like Gaze, Voice, Smartphone screen tap/gesture, Smart watch screen/buttons ) individually or in the various combination.</p>
<strong> Example 1 :</strong> User can gaze(select) at the Open/Dismiss button and then press(activate) the smartphone/smartwatch screen.<br>
<strong> Example 2 :</strong> User can gaze(select) at the Open/Dismiss button and then use voice command(activate) to confirm the selection <br>

![Using-Phone-to-Interact1](https://user-images.githubusercontent.com/65128826/232402112-7946ddbe-022b-4b33-8941-687069c73f57.gif)<br>
<p>
Instead of raising the hand to interact while traveling in public transport, the user can use their smartphone to interact with the notification.
</p>
